{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An AI Agent That Learns Emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don Crowley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSC 594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a Neural Network to Answer Yes/No Questions About Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for this section was taken and modified from: https://medium.com/illuin/deep-learning-has-almost-all-the-answers-yes-no-question-answering-with-transformers-223bebb70189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./opt/anaconda3/lib/python3.7/site-packages (1.5.0)\n",
      "Requirement already satisfied: torchvision in ./opt/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: future in ./opt/anaconda3/lib/python3.7/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (from torch) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in ./opt/anaconda3/lib/python3.7/site-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: transformers in ./opt/anaconda3/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in ./opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (1.18.1)\n",
      "Copying gs://boolq/train.jsonl...\n",
      "- [1 files][  6.2 MiB/  6.2 MiB]                                                \n",
      "Operation completed over 1 objects/6.2 MiB.                                      \n",
      "Copying gs://boolq/dev.jsonl...\n",
      "/ [1 files][  2.1 MiB/  2.1 MiB]                                                \n",
      "Operation completed over 1 objects/2.1 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "\n",
    "!gsutil cp gs://boolq/train.jsonl .\n",
    "!gsutil cp gs://boolq/dev.jsonl ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a GPU if you have one available (Runtime -> Change runtime type -> GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(26)\n",
    "np.random.seed(26)\n",
    "torch.manual_seed(26)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\") \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "model.to(device) # Send the model to the GPU if we have one\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(tokenizer, questions, passages, max_length):\n",
    "    \"\"\"Encode the question/passage pairs into features than can be fed to the model.\"\"\"\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for question, passage in zip(questions, passages):\n",
    "        encoded_data = tokenizer.encode_plus(question, passage, max_length=max_length, pad_to_max_length=True, truncation_strategy=\"longest_first\")\n",
    "        encoded_pair = encoded_data[\"input_ids\"]\n",
    "        attention_mask = encoded_data[\"attention_mask\"]\n",
    "\n",
    "        input_ids.append(encoded_pair)\n",
    "        attention_masks.append(attention_mask)\n",
    "\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "# Loading data\n",
    "#train_data_df = pd.read_json(\"/content/train.jsonl\", lines=True, orient='records')\n",
    "#dev_data_df = pd.read_json(\"/content/dev.jsonl\", lines=True, orient=\"records\")\n",
    "train_data_df = pd.read_json(\"train.jsonl\", lines=True, orient='records')\n",
    "dev_data_df = pd.read_json(\"dev.jsonl\", lines=True, orient=\"records\")\n",
    "\n",
    "passages_train = train_data_df.passage.values\n",
    "questions_train = train_data_df.question.values\n",
    "answers_train = train_data_df.answer.values.astype(int)\n",
    "\n",
    "passages_dev = dev_data_df.passage.values\n",
    "questions_dev = dev_data_df.question.values\n",
    "answers_dev = dev_data_df.answer.values.astype(int)\n",
    "\n",
    "# Encoding data\n",
    "max_seq_length = 256\n",
    "input_ids_train, attention_masks_train = encode_data(tokenizer, questions_train, passages_train, max_seq_length)\n",
    "input_ids_dev, attention_masks_dev = encode_data(tokenizer, questions_dev, passages_dev, max_seq_length)\n",
    "\n",
    "train_features = (input_ids_train, attention_masks_train, answers_train)\n",
    "dev_features = (input_ids_dev, attention_masks_dev, answers_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_features_tensors = [torch.tensor(feature, dtype=torch.long) for feature in train_features]\n",
    "dev_features_tensors = [torch.tensor(feature, dtype=torch.long) for feature in dev_features]\n",
    "\n",
    "train_dataset = TensorDataset(*train_features_tensors)\n",
    "dev_dataset = TensorDataset(*dev_features_tensors)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "dev_sampler = SequentialSampler(dev_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "dev_dataloader = DataLoader(dev_dataset, sampler=dev_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step took roughly 12 hours running on my laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [15:16:36<00:00, 10999.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "grad_acc_steps = 1\n",
    "train_loss_values = []\n",
    "dev_acc_values = []\n",
    "\n",
    "for _ in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "\n",
    "  # Training\n",
    "  epoch_train_loss = 0 # Cumulative loss\n",
    "  model.train()\n",
    "  model.zero_grad()\n",
    "\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "      input_ids = batch[0].to(device)\n",
    "      attention_masks = batch[1].to(device)\n",
    "      labels = batch[2].to(device)     \n",
    "\n",
    "      outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
    "\n",
    "      loss = outputs[0]\n",
    "      loss = loss / grad_acc_steps\n",
    "      epoch_train_loss += loss.item()\n",
    "\n",
    "      loss.backward()\n",
    "      \n",
    "      if (step+1) % grad_acc_steps == 0: # Gradient accumulation is over\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Clipping gradients\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "  epoch_train_loss = epoch_train_loss / len(train_dataloader)          \n",
    "  train_loss_values.append(epoch_train_loss)\n",
    "  \n",
    "  # Evaluation\n",
    "  epoch_dev_accuracy = 0 # Cumulative accuracy\n",
    "  model.eval()\n",
    "\n",
    "  for batch in dev_dataloader:\n",
    "    \n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_masks = batch[1].to(device)\n",
    "    labels = batch[2]\n",
    "                \n",
    "    with torch.no_grad():        \n",
    "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
    "                    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    predictions = np.argmax(logits, axis=1).flatten()\n",
    "    labels = labels.numpy().flatten()\n",
    "    \n",
    "    epoch_dev_accuracy += np.sum(predictions == labels) / len(labels)\n",
    "\n",
    "  epoch_dev_accuracy = epoch_dev_accuracy / len(dev_dataloader)\n",
    "  dev_acc_values.append(epoch_dev_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My predictions didn't work out as well as in the example.  I think there is still something useful here, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Did the Denver Broncos win the Super Bowl 50?, Yes: 0.97, No: 0.03\n",
      "Question: Did the Carolina Panthers win the Super Bowl 50?, Yes: 0.98, No: 0.02\n",
      "Question: Was the Super Bowl played at Levi's Stadium?, Yes: 0.97, No: 0.03\n",
      "Question: Was the Super Bowl 50 played in Las Vegas?, Yes: 0.96, No: 0.04\n",
      "Question: Was the Super Bowl 50 played in February?, Yes: 0.97, No: 0.03\n",
      "Question: Was the Super Bowl 50 played in March?, Yes: 0.93, No: 0.07\n",
      "Question: Is Illuin the answer to your strategic needs?, Yes: 0.95, No: 0.05\n"
     ]
    }
   ],
   "source": [
    "def predict(question, passage):\n",
    "  sequence = tokenizer.encode_plus(passage, question, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "  \n",
    "  logits = model(sequence)[0]\n",
    "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
    "  proba_yes = round(probabilities[1], 2)\n",
    "  proba_no = round(probabilities[0], 2)\n",
    "\n",
    "  print(f\"Question: {question}, Yes: {proba_yes}, No: {proba_no}\")\n",
    "  \n",
    "passage_superbowl = \"\"\"Super Bowl 50 was an American football game to determine the champion of the National Football League\n",
    "                    (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated\n",
    "                    the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title.\n",
    "                    The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara,\n",
    "                    California. As this was the 50th Super Bowl, the league emphasized the 'golden anniversary' with various\n",
    "                    gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game\n",
    "                    with Roman numerals (under which the game would have been known as 'Super Bowl L'), so that the logo could\n",
    "                    prominently feature the Arabic numerals 50.\"\"\"\n",
    " \n",
    "passage_illuin = \"\"\"Illuin designs and builds solutions tailored to your strategic needs using Artificial Intelligence\n",
    "                  and the new means of human interaction this technology enables.\"\"\"\n",
    "\n",
    "superbowl_questions = [\n",
    "\"Did the Denver Broncos win the Super Bowl 50?\", \n",
    "\"Did the Carolina Panthers win the Super Bowl 50?\",\n",
    "\"Was the Super Bowl played at Levi's Stadium?\", \n",
    "\"Was the Super Bowl 50 played in Las Vegas?\", \n",
    "\"Was the Super Bowl 50 played in February?\", \"Was the Super Bowl 50 played in March?\"\n",
    "]\n",
    "\n",
    "question_illuin = \"Is Illuin the answer to your strategic needs?\"\n",
    "\n",
    "for s_question in superbowl_questions:\n",
    "  predict(s_question, passage_superbowl)\n",
    "\n",
    "predict(question_illuin, passage_illuin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this model as the ynmodel\n",
    "ynmodel = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./opt/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (46.0.0.post20200309)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in ./opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/donaldcrowley/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/donaldcrowley/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in ./opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in ./opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Requirement already satisfied: transformers in ./opt/anaconda3/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece in ./opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: python-Levenshtein in ./opt/anaconda3/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from python-Levenshtein) (46.0.0.post20200309)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import pickle\n",
    "from collections import Counter\n",
    "spacy.load('/Users/donaldcrowley/PycharmProjects/untitled2/env/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.2.0')\n",
    "#import en_core_web_sm\n",
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "!pip install transformers\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "model2 = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "from transformers import BertTokenizer\n",
    "tokenizer2 = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "import pandas as pd\n",
    "!pip install python-Levenshtein\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 'Person'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person class tells us a little about each person in the story.  The AI can store the persons name, the user's opinion of that person (a numerical score based on sentiment analysis), the opinions strength, and some adjectives that the user used to describe the person.  This could definitely be expanded to contain more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a class 'Person'\n",
    "#this will enable the AI to learn about the user's opinion on people in the text\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, useropinion, opinionstrength, descriptions):\n",
    "        self.name = name\n",
    "        self.useropinion = useropinion\n",
    "        self.opinionstrength = opinionstrength\n",
    "        #create a list of descriptions of this new person\n",
    "        self.descriptions = descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to find names in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will help us to identify the characters in the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_finder(story):\n",
    "    nlp = spacy.load('/Users/donaldcrowley/PycharmProjects/untitled2/env/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.2.0')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    doc = nlp(story)\n",
    "    sentences = [x for x in doc.sents]\n",
    "    #return the names in the story\n",
    "    names = (dict([(str(x), x.label_) for x in nlp(str(sentences[0:])).ents]))\n",
    "    return(set(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to build and store user's opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an initial opinion on someone\n",
    "def build_opinions(names, peoplelist):\n",
    "    for i in names:\n",
    "        if i not in peoplelist:\n",
    "            #see what the user thinks about this person who is new to the agent\n",
    "            opinionbuild = input(\"what do you think about \" + i + \"? If this is not a name please type: not a name\\n\")\n",
    "            if opinionbuild != \"not a name\":\n",
    "\n",
    "              text = nltk.word_tokenize(opinionbuild)\n",
    "              tagged = nltk.pos_tag(text)\n",
    "              emplist = []\n",
    "              for j in tagged:\n",
    "                  if j[1] == 'JJ':\n",
    "                      emplist.append(j[0])\n",
    "              peoplelist.append(Person(i, TextBlob(opinionbuild).sentiment[0], TextBlob(opinionbuild).sentiment[1], emplist))\n",
    "        else:\n",
    "            print(\"you described \" + i +\" as \")\n",
    "            for word in peoplelist[0].descriptions:\n",
    "                print(word)\n",
    "    return(peoplelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    #overwrite the existing database\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "#uses the save_object file to save the file if user requests it\n",
    "def savepeople():\n",
    "    saveYN = input(\"Would you like to save your people opinions from this story? \\n\")\n",
    "    if saveYN == \"y\" or saveYN == \"yes\" or saveYN == \"Yes\":\n",
    "        save_object(peoplelist, 'peoplelist.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to load in saved information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in our list of people, otherwise, create a blank list\n",
    "def load_people():\n",
    "  try:\n",
    "    peoplelist = pickle.load(open(\"peoplelist.pkl\", \"rb\"))\n",
    "  except:\n",
    "    peoplelist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use BERT to create a function to get extractive answers from text.  \n",
    "I modified code from this website:   https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note:  model2 and tokenizer2 are associated with the pre trained fine-tuned extractive question answering neural network.  \n",
    "\n",
    "model and tokenizer are associated with the fine-tuned yes/no question answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code takes a question and then identifies and prints\n",
    "#the words within the text that answer the question\n",
    "\n",
    "def answer_question(question, answer_text):\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer2.encode(question, answer_text)\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer2.sep_token_id)\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0] * num_seg_a + [1] * num_seg_b\n",
    "    # There should be a segment_id for every input token.\n",
    "    #the assert function checks that something is true, otherwise it raises the error message provided\n",
    "    assert len(segment_ids) == len(input_ids), \"missing a segment id for the input token\"\n",
    "\n",
    "\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model2(torch.tensor([input_ids]),  # The tokens representing our input text.\n",
    "                                     token_type_ids=torch.tensor(\n",
    "                                         [segment_ids]))  # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # the tokens with the highest start and end scores emcompass the likeliest start and end\n",
    "    #to the answer of the question\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer2.convert_ids_to_tokens(input_ids)\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        # If it's a subword token(denoted by ## in BERT), then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "    #print('Answer: \"' + answer + '\"')\n",
    "    #return(str(answer))\n",
    "    return (answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an emotion of that type'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"what are we really talking about?\", \"As discussed above, when we speak of an emotion generated by the system we are really talking about an emotion of that type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictyn(question, passage):\n",
    "  sequence = tokenizer.encode_plus(passage, question, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "  \n",
    "  logits = ynmodel(sequence)[0]\n",
    "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
    "  proba_yes = round(probabilities[1], 2)\n",
    "  proba_no = round(probabilities[0], 2)\n",
    "    \n",
    "  #Our prediction wasn't working super well above, but I think\n",
    "  #we can just say if the predicted probability of no is higher\n",
    "    #there is a good chance the answer is no, even if the absolute probability\n",
    "    #of 'yes' is high\n",
    "  if proba_yes > proba_no:\n",
    "    return (\"yes\")\n",
    "  else:\n",
    "    return(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few simple predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "print(predictyn(\"did the bears win the superbowl?\", \"in 1988 the bears won the superbowl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "print(predictyn(\"did the bears win the superbowl?\", \"The bears did not win the superbowl.  They lost\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the goal_query function prints out whether the person in the story achieved their goal and predicts the user's emotional response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if character's the story achieved their a goal or not\n",
    "\n",
    "\n",
    "def goal_query(person, story):\n",
    "  ques = \"what was \" + str(person.name) + \" supposed to do?\"\n",
    "  answer1 = answer_question(ques, str(story))\n",
    "  question_affirmative = \"did \" + str(person.name) + \" \"+ str(answer1) + \"?\"\n",
    "  question_negative = \"did \" + str(person.name) + \" not \"+ str(answer1) + \"?\"\n",
    "  #used the ratio to answer a yes/no question about whether that goal was achieved\n",
    "  #going through sentence by sentence and getting the max seemed to be a more effective way of doing this\n",
    "  #so the 'levensh' function does that  \n",
    "\n",
    "  if predictyn(question_affirmative, answer_question(question_affirmative, story)) > predictyn(question_negative, answer_question(question_negative, story)):\n",
    "    #print(person.name + \" achieved the goal of \" + str(answer1) + \"!\\n.  You are happy for \" + person.name + \" for achieving a goal.\")\n",
    "    emotion = \"happy-for\"\n",
    "    response = person.name + \" achieved the goal of \" + str(answer1) + \"!\\n.  You are happy for \" + person.name + \" for achieving a goal.\"\n",
    "    return(emotion, response)\n",
    "  else:\n",
    "    #print(person.name + \" did not achieve the goal of \" + \"\\'\" + str(answer1) + \"\\'\" +\"\\n\"+ \"  You are sorry for \" + person.name + \" for not achieving a goal.\")\n",
    "    emotion = \"sorry-for\"\n",
    "    response = person.name + \" did not achieve the goal of \" + \"\\'\" + str(answer1) + \"\\'\" +\"\\n\"+ \"  You are sorry for \" + person.name + \" for not achieving a goal.\"\n",
    "    return(emotion, response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off with a simple story of Lauren forgetting to get milk at the grocery store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#story of Lauren failing to pick up the milk\n",
    "story = \"1. Lauren went to the store to pick up milk because we are out of milk.  However, Lauren forgot to get the milk.  Instead, Lauren met her friend Kate and had a glass of wine.\"\n",
    "#an alternate story of Lauren picking up the milk successfully\n",
    "story1 = \"it was a bright and sunny day.  Traffic was bad on the expressway.  Lauren went to the store to buy bread.  However, Lauren forgot and did not buy the bread.  Instead she bought cookies.\"\n",
    "\n",
    "story2 = \"2. Lauren went to the store to pick up milk.  Lauren picked up the milk and also bought some cookies.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lauren did not achieve the goal of 'pick up milk'\n",
      "  You are sorry for Lauren for not achieving a goal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sorry-for'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to test this out let's creat a person object Lauren\n",
    "Lauren = Person(\"Lauren\", .6, .1, [\"kind\", \"smart\"])\n",
    "goal_query(Lauren, story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object 'user_goal' will store the user's goals and whether or not they are mutually exclusive, non exclusive, or neither "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user_goal:\n",
    "    def __init__(self, goal, exclusive):\n",
    "        #what is the goal\n",
    "        self.goal = goal\n",
    "        #is it mutually exclusive (jealousy)?  value = 1\n",
    "        #is it a desired non-exclusive(envy)?  value = 2\n",
    "        #or neither.  A goal that can be shared by user and other person?  value = 0\n",
    "        self.exclusive = exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user_goal_query function will determine if the user shared a goal that was achieved by a friend or rival in the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_goal_query(user_goals, story):\n",
    "    #check for each goal against the story and see if it was realized or not\n",
    "    for goal in user_goals:\n",
    "        questionY = \"did I\" + goal + \"?\"\n",
    "        questionN = \"did I not\" + goal + \"?\"\n",
    "        if predictyn(questionY, story) > predictyn(questionN, story):\n",
    "            return (goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_query(story, emotion):\n",
    "    correctYN = input(\"was the predicted emotion correct? y/n \\n\")\n",
    "    if correctYN == \"n\":\n",
    "        actual_emotion = input(\"What was your actual emotional response? \\n\")\n",
    "        altQuestion = input(\"what question could I have asked about this text to gauge my emotional reaction?  type 'n' if not. \\n\")\n",
    "        \n",
    "        if altQuestion == 'n':\n",
    "            usergoal = input(\"if you had a goal in this story, what was it? \\n\")\n",
    "            if usergoal:\n",
    "                goalfeatures = input(\"is this a mutually exclusive goal?  enter 1 \\nis this a non-exclusive goal?  enter 2\\nOr neither?  enter 0\\n\")\n",
    "            return(actual_emotion, usergoal, goalfeatures, 0)\n",
    "        else:\n",
    "            usergoal = input(\"if you had a goal in this story, what was it? \\n\")\n",
    "        return(actual_emotion, 0, 0, altQuestion)\n",
    "    else:\n",
    "        print(\"great, you and I are on the same page!\\n\")\n",
    "        return(0,0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put these functions together and try to build up an agent that can read passages of text and learn to interpret them emotionally with the help of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_goal_list = []\n",
    "memories_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def AI_Agent(story, opinionlist, user_goal_list):\n",
    "    # Emotion is what we want to predict\n",
    "    Emotion = 0\n",
    "\n",
    "    # ask user whether to load in saved people:\n",
    "    loadyn = input(\"Would you like to load in your saved list of people?(y/n)\\n\")\n",
    "    if loadyn.lower() == \"y\" or loadyn.lower() == \"yes\":\n",
    "        loadpeople()\n",
    "\n",
    "        ######################################################################\n",
    "    ###Start off looking for emotions found within 'fortunes of others'###\n",
    "    ######################################################################\n",
    "\n",
    "    # identify the names in the story\n",
    "    # and build opinions of each person\n",
    "    opinions = build_opinions(name_finder(story), opinionlist)\n",
    "    print(\"\\n Here is our story that provokes an emotion.  Let's see if we are both on the same page! \\n\")\n",
    "    print(story)\n",
    "    # each name in opinions is an object that contains:\n",
    "    # 1 name\n",
    "    # 2 user opinion\n",
    "    # 3 the strength of that opinion\n",
    "    # 4 any adjectives used to describe the person\n",
    "\n",
    "    # check if a person in the story is a friend, neutral, or a rival\n",
    "    # this section will test for Fortunes-of-Other's emotions\n",
    "    for person in set(opinions):\n",
    "        \n",
    "        # we'll use a sentiment analysis of .5 as the cutoff for friend, but this can\n",
    "        # be changed\n",
    "\n",
    "        ################\n",
    "        #####friend#####\n",
    "        ################\n",
    "        if person.useropinion > .5:\n",
    "           \n",
    "\n",
    "            # first try to determine if a goal has been achieved by the friend\n",
    "            # if the goal has been achieved but the user has resentment about not\n",
    "            # also achieving the goal, the user could either be jealous or envious\n",
    "            emotion_predict, response = goal_query(person, story)\n",
    "            print(response)\n",
    "            if emotion_predict == \"happy_for\":\n",
    "                \n",
    "\n",
    "                # now check if the user wanted to obtain the same goal\n",
    "                useGoal = user_goal_query(user_goals, story)\n",
    "                # if so, are we envious or jealous?\n",
    "                if useGoal == True:\n",
    "                    if useGoal.exclusive == 1:\n",
    "                        emotion_predict = \"jealous of\"\n",
    "                        # return(emotion_predict)\n",
    "                    elif useGoal.exclusive == 2:\n",
    "                        emotion_predict = \"envious of\"\n",
    "                        # return(emotion_predict)\n",
    "                else:\n",
    "                    print(response)\n",
    "\n",
    "\n",
    "            if emotion_predict == \"sorry for\":\n",
    "                print(response)\n",
    "\n",
    "        ###############\n",
    "        #####rival#####\n",
    "        ###############\n",
    "\n",
    "        if person.useropinion < (-.5):\n",
    "    # in this case we are gauging the response to a person\n",
    "    # that the user doesn't especially like\n",
    "            emotion_predict, response = goal_query(person, story)\n",
    "            if emotion_predict == \"happy_for\":\n",
    "        # so this person achieved their goal, but since the\n",
    "        # user doesn't like them, we'll flip the opinion to negative\n",
    "                emotion_predict = \"resentment\"\n",
    "    # now what if the rival didn't achieve their goal:\n",
    "            else:\n",
    "                emotion_predict = 'gloating'\n",
    "                print(response.replace(\"sorry for\", \"gloating at\"))\n",
    "\n",
    "    #if\n",
    "    emotion_actual, usergoal, newfeature, Alt_question = user_query(story, emotion_predict)\n",
    "    #if the user has given a new goal, we add it to the list of user's goals\n",
    "    if usergoal:\n",
    "        newgoal1 = user_goal(usergoal, newfeature)\n",
    "        user_goal_list.append(newgoal)\n",
    "    #if our actual emotion is our predicted emotion\n",
    "    if emotion_actual == 0:\n",
    "        emotion_actual = emotion_predict\n",
    "        \n",
    "    savepeople()\n",
    "    \n",
    "    \n",
    "    return(story, name_finder(story), emotion_predict, emotion_actual)\n",
    "\n",
    "# now get feedback from the user on if this interpretation was correct\n",
    "#user_query_interp(story, person, Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-1d85df0e9ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAI_Agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-259-e3116a13711a>\u001b[0m in \u001b[0;36mAI_Agent\u001b[0;34m(story, opinionlist, user_goal_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ask user whether to load in saved people:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloadyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Would you like to load in your saved list of people?(y/n)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloadyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloadyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloadpeople\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a,b,c,d = AI_Agent(story1, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was a bright and sunny day.  Traffic was bad on the expressway.  Lauren went to the store to buy bread.  However, Lauren forgot and did not buy the bread.  Instead she bought cookies. {'Lauren'} sorry-for jealous\n"
     ]
    }
   ],
   "source": [
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
